#!/usr/bin/env python3
"""
ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ù„Ù„ØªÙˆØµÙŠØ§Øª
"""

import sys
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from datetime import datetime

import os

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from backend.data.database import Database
from backend.models.ml_model import StockMLModel

def create_target(df):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡Ø¯Ù (Buy/Sell/Hold)"""
    # Ù†Ø¸Ø±Ø© Ù„Ù„Ø£Ù…Ø§Ù… 5 Ø£ÙŠØ§Ù…
    df['future_return'] = df['close'].shift(-5) / df['close'] - 1
    
    # ØªØµÙ†ÙŠÙ
    conditions = [
        df['future_return'] > 0.03,  # Ø§Ø±ØªÙØ§Ø¹ > 3% = Buy
        df['future_return'] < -0.03,  # Ø§Ù†Ø®ÙØ§Ø¶ > 3% = Sell
    ]
    choices = ['buy', 'sell']
    df['target'] = np.select(conditions, choices, default='hold')
    
    return df

def prepare_training_data(db):
    """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    print("ğŸ“Š Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©...")
    
    # Ø¬Ù„Ø¨ Ø¢Ø®Ø± 500 ÙŠÙˆÙ…
    data = db.get_all_historical_data(days=500)
    
    if not data:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª!")
        return None
    
    df = pd.DataFrame(data)
    print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(df)} Ø³Ø¬Ù„ Ù…Ù† {df['symbol'].nunique()} Ø³Ù‡Ù…")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³Ù‡Ù…
    ml_model = StockMLModel()
    all_data = []
    
    for symbol in df['symbol'].unique():
        stock_df = df[df['symbol'] == symbol].copy()
        stock_df = stock_df.sort_values('date')
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        stock_df = ml_model.calculate_technical_indicators(stock_df)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡Ø¯Ù
        stock_df = create_target(stock_df)
        
        all_data.append(stock_df)
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    final_df = pd.concat(all_data, ignore_index=True)
    final_df = final_df.dropna()
    
    print(f"âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(final_df)} Ø¹ÙŠÙ†Ø©")
    
    return final_df

def train_model(df):
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    print("\nğŸ¤– Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    
    # Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ù…Ø¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©)
    features = [
        'rsi', 'macd', 'macd_signal', 'macd_diff',
        'sma_20', 'sma_50', 'ema_12',
        'bb_width', 'atr', 'volume_ratio',
        'price_change', 'price_change_5d',
        'stoch_k', 'stoch_d', 'adx', 'obv_ema'
    ]
    
    X = df[features]
    y = df['target']
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"ğŸ“Š Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(X_train)} Ø¹ÙŠÙ†Ø©")
    print(f"ğŸ“Š Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(X_test)} Ø¹ÙŠÙ†Ø©")
    print(f"ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª:\n{y_train.value_counts()}")
    
    # Hyperparameter Tuning
    print("\nâ³ Ø¬Ø§Ø±ÙŠ Hyperparameter Tuning...")
    
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [10, 15, 20],
        'min_samples_split': [10, 20],
        'min_samples_leaf': [5, 10]
    }
    
    base_model = RandomForestClassifier(
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    
    grid_search = GridSearchCV(
        base_model,
        param_grid,
        cv=3,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    
    print(f"\nâœ… Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {grid_search.best_params_}")
    
    model = grid_search.best_estimator_
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nâœ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {accuracy*100:.2f}%")
    print("\nğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:")
    print(classification_report(y_test, y_pred))
    
    # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ“Š Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª:")
    print(feature_importance.to_string(index=False))
    
    return model, features

def main():
    print("=" * 70)
    print("ğŸš€ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ù„Ù„ØªÙˆØµÙŠØ§Øª")
    print("=" * 70)
    
    db = Database()
    
    try:
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = prepare_training_data(db)
        
        if df is None or len(df) < 1000:
            print("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©!")
            return
        
        # ØªØ¯Ø±ÙŠØ¨
        model, features = train_model(df)
        
        # Ø­ÙØ¸
        ml_model = StockMLModel()
        ml_model.model = model
        ml_model.features = features
        ml_model.save_model()
        
        print("\n" + "=" * 70)
        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        print("=" * 70)
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        db.close()

if __name__ == "__main__":
    main()
