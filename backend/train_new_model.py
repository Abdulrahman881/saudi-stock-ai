#!/usr/bin/env python3
"""
ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ø¬Ø¯ÙŠØ¯ Ù„Ù„ØªÙˆØµÙŠØ§Øª
"""

import sys
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import joblib
from datetime import datetime, timedelta

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ù€ modules
sys.path.append('/home/ubuntu/projects/saudi-stock-ai/backend')

from data.database import Database

def calculate_technical_indicators(df):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©"""
    
    # RSI (14 ÙŠÙˆÙ…)
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp1 = df['close'].ewm(span=12, adjust=False).mean()
    exp2 = df['close'].ewm(span=26, adjust=False).mean()
    df['macd'] = exp1 - exp2
    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
    df['macd_diff'] = df['macd'] - df['macd_signal']
    
    # Moving Averages
    df['sma_20'] = df['close'].rolling(window=20).mean()
    df['sma_50'] = df['close'].rolling(window=50).mean()
    df['ema_12'] = df['close'].ewm(span=12, adjust=False).mean()
    
    # Bollinger Bands
    df['bb_middle'] = df['close'].rolling(window=20).mean()
    bb_std = df['close'].rolling(window=20).std()
    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
    
    # ATR (Average True Range)
    high_low = df['high'] - df['low']
    high_close = np.abs(df['high'] - df['close'].shift())
    low_close = np.abs(df['low'] - df['close'].shift())
    ranges = pd.concat([high_low, high_close, low_close], axis=1)
    true_range = np.max(ranges, axis=1)
    df['atr'] = true_range.rolling(14).mean()
    
    # Volume Ratio
    df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
    
    # Price Change
    df['price_change'] = df['close'].pct_change()
    df['price_change_5d'] = df['close'].pct_change(periods=5)
    
    return df

def create_target(df):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡Ø¯Ù (Buy/Sell/Hold) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©"""
    # Ù†Ø¸Ø±Ø© Ù„Ù„Ø£Ù…Ø§Ù… 5 Ø£ÙŠØ§Ù…
    df['future_return'] = df['close'].shift(-5) / df['close'] - 1
    
    # ØªØµÙ†ÙŠÙ
    conditions = [
        df['future_return'] > 0.03,  # Ø§Ø±ØªÙØ§Ø¹ Ø£ÙƒØ«Ø± Ù…Ù† 3% = Buy
        df['future_return'] < -0.03,  # Ø§Ù†Ø®ÙØ§Ø¶ Ø£ÙƒØ«Ø± Ù…Ù† 3% = Sell
    ]
    choices = ['buy', 'sell']
    df['target'] = np.select(conditions, choices, default='hold')
    
    return df

def prepare_training_data(db):
    """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    print("ğŸ“Š Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    # Ø¬Ù„Ø¨ Ø¢Ø®Ø± 500 ÙŠÙˆÙ… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø³Ù‡Ù…
    query = """
    SELECT symbol, date, open, high, low, close, volume
    FROM historicalDailyPrices
    WHERE date >= DATE_SUB(CURDATE(), INTERVAL 500 DAY)
    ORDER BY symbol, date
    """
    
    df = pd.read_sql(query, db.connection)
    
    if df.empty:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©!")
        return None
    
    print(f"âœ… ØªÙ… Ø¬Ù„Ø¨ {len(df)} Ø³Ø¬Ù„ Ù…Ù† {df['symbol'].nunique()} Ø³Ù‡Ù…")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø³Ù‡Ù… Ø¹Ù„Ù‰ Ø­Ø¯Ø©
    all_data = []
    
    for symbol in df['symbol'].unique():
        stock_df = df[df['symbol'] == symbol].copy()
        stock_df = stock_df.sort_values('date')
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        stock_df = calculate_technical_indicators(stock_df)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‡Ø¯Ù
        stock_df = create_target(stock_df)
        
        all_data.append(stock_df)
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    final_df = pd.concat(all_data, ignore_index=True)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN
    final_df = final_df.dropna()
    
    print(f"âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(final_df)} Ø¹ÙŠÙ†Ø©")
    
    return final_df

def train_model(df):
    """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest"""
    print("\nğŸ¤– Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª
    features = [
        'rsi', 'macd', 'macd_signal', 'macd_diff',
        'sma_20', 'sma_50', 'ema_12',
        'bb_width', 'atr', 'volume_ratio',
        'price_change', 'price_change_5d'
    ]
    
    X = df[features]
    y = df['target']
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(X_train)} Ø¹ÙŠÙ†Ø©")
    print(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(X_test)} Ø¹ÙŠÙ†Ø©")
    print(f"ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª:")
    print(y_train.value_counts())
    
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=20,
        min_samples_leaf=10,
        class_weight='balanced',  # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†
        random_state=42,
        n_jobs=-1
    )
    
    print("\nâ³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    model.fit(X_train, y_train)
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nâœ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {accuracy*100:.2f}%")
    print("\nğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:")
    print(classification_report(y_test, y_pred))
    
    # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ“Š Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª:")
    print(feature_importance.to_string(index=False))
    
    return model, features

def main():
    print("=" * 60)
    print("ğŸš€ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Random Forest Ù„Ù„ØªÙˆØµÙŠØ§Øª")
    print("=" * 60)
    
    # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    db = Database()
    
    try:
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df = prepare_training_data(db)
        
        if df is None or len(df) < 1000:
            print("âŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨!")
            print("ğŸ’¡ ØªØ­ØªØ§Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 1000 Ø¹ÙŠÙ†Ø©")
            return
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model, features = train_model(df)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model_path = '/tmp/stock_model.pkl'
        model_data = {
            'model': model,
            'features': features,
            'trained_at': datetime.now().isoformat(),
            'samples': len(df)
        }
        
        joblib.dump(model_data, model_path)
        print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {model_path}")
        
        print("\n" + "=" * 60)
        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        db.close()

if __name__ == "__main__":
    main()
